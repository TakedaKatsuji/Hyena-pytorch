{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# hyenaの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "from torchinfo import summary"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Projection  \n",
    "\n",
    "入力をN個にProjection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Projection(nn.Module):\n",
    "    def __init__(self,\n",
    "                 embed_dim: int, #  D:model width モデルの並列数（チャンネル？）\n",
    "                 order: int = 2, #　N:入力を射影する数\n",
    "                 kernel_size: int = 3,\n",
    "                 stride: int = 1,\n",
    "                 padding: int = 2\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        \n",
    "        hidden_size = (order + 1) * embed_dim #線形層のunit数\n",
    "        self.linear = nn.Linear(embed_dim, hidden_size) #embed_dim -> hidden_size\n",
    "        self.short_conv = nn.Conv1d(\n",
    "            in_channels=hidden_size,\n",
    "            out_channels=hidden_size,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding,\n",
    "            groups=hidden_size\n",
    "        )\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "    def forward(self, u: Tensor):\n",
    "        # B: batch size, L: seq len, E: embed dim, N: order of hyena\n",
    "        L = u.shape[1]\n",
    "        u = self.linear(u) # embed_dim -> hidden_size\n",
    "                           # (B, L, E) -> (B, (N+1)*E, L)   H=(N+1)*E\n",
    "        u = rearrange(u, \"B L H -> B H L\") #　H: hidden_size\n",
    "        u = self.short_conv(u)[..., :L]\n",
    "        return u.chunk(self.hidden_size, dim=1) # v,x1,x2,x3 に分割# ( B, (N+1)*E, L) ->  [(B, E, L)] * (N+1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 224, 1])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "enbed_dim = 1 #model_width\n",
    "order = 3 #N=5 \n",
    "\n",
    "proj = Projection(embed_dim=enbed_dim, order=order) \n",
    "u = torch.randn(1, 224, 1, requires_grad=True) #(B=1, L=224, E=1) \n",
    "u.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 224, 4])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(in_features=1, out_features=(3+1)*1)\n",
    "linear(u).shape # B,L,H "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 224])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_rea = rearrange(linear(u), \"B L H -> B H L\") # B, H, L\n",
    "u_rea.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 224])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "short_conv = nn.Conv1d(\n",
    "            in_channels=(3+1)*1,\n",
    "            out_channels=(3+1)*1,\n",
    "            kernel_size=3,\n",
    "            stride=1,\n",
    "            padding=2,\n",
    "            groups=(3+1)*1)\n",
    "\n",
    "sconv = short_conv(u_rea)[...,:224]\n",
    "sconv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 224])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sconv.chunk((3+1)*1,dim=1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, embed_dim: int, max_seq_len: int):\n",
    "        assert embed_dim % 2 == 1, \"`embed_dim` must be odd\"\n",
    "        super().__init__()\n",
    "        # L: seq len, Ep: pos embed dim, K: (Et-1)//2\n",
    "        t = torch.linspace(0, 1, steps=max_seq_len).unsqueeze(-1) # -> (L, 1)\n",
    "        t_pos = torch.arange(0, max_seq_len, dtype=torch.float).unsqueeze(-1) # -> (L, 1)\n",
    "        K = (embed_dim - 1) // 2\n",
    "        k = torch.linspace(0, K - 1, steps=K).unsqueeze(0) # -> (1, K)\n",
    "        z = torch.exp(1j * 2 * np.pi * k * t_pos / max_seq_len) # -> (L, K)\n",
    "        self.t = nn.Parameter(t.view(1, 1, max_seq_len), requires_grad=False) # -> (1, 1, L)\n",
    "        self.z = nn.Parameter(\n",
    "            torch.cat([t, z.real, z.imag], dim=-1), # -> (L, Ep)\n",
    "        )\n",
    "\n",
    "    def forward(self, seq_len: int) -> tuple[Tensor, Tensor]:\n",
    "        return self.t[..., :seq_len], self.z[:seq_len, :]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embed_dim = 1\n",
    "max_seq_len = 224\n",
    "pe = PositionalEncoding(embed_dim=embed_dim, max_seq_len=max_seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 224])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pe(224)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sin(nn.Module):\n",
    "    def __init__(self, embed_dim: int, freq: float = 8.0, learn: bool = True):\n",
    "        super().__init__()\n",
    "        self.freq = nn.Parameter(freq * torch.ones(1, embed_dim), requires_grad=learn)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        # L: seq len, E: embed dim\n",
    "        return torch.sin(self.freq * x) # -> (L, E)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExponentialDecayWindow(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        embed_dim: int,\n",
    "        fast_decay_t: float = 0.3,\n",
    "        slow_decay_t: float = 1.5,\n",
    "        target: float = 1e-2,\n",
    "        shift: float = 0.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        max_decay = np.log(target) / fast_decay_t\n",
    "        min_decay = np.log(target) / slow_decay_t\n",
    "        self.alphas = nn.Parameter(\n",
    "            torch.linspace(min_decay, max_decay, steps=embed_dim).view(1, embed_dim, 1)\n",
    "        )\n",
    "        self.shift = shift\n",
    "\n",
    "    def forward(self, x: Tensor, t: Tensor) -> Tensor:\n",
    "        # L: seq len, E: embed dim, N: order of hyena\n",
    "        L = x.shape[-1]\n",
    "        decay = torch.exp(self.alphas * t)[..., :L] # -> (1, E, L)\n",
    "        x *= decay + self.shift\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyenaFilter(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pos_embed_dim: int,\n",
    "        max_seq_len: int,\n",
    "        seq_embed_dim: int,\n",
    "        order: int = 2,\n",
    "        fnn_depth: int = 4,\n",
    "        fnn_hidden_size: int = 64,\n",
    "        freq: float = 10.0,\n",
    "        learn: bool = True,\n",
    "        fast_decay_t: float = 0.3,\n",
    "        slow_decay_t: float = 1.5,\n",
    "        target: float = 1e-2,\n",
    "        shift: float = 0.0\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert fnn_depth > 2, \"fnn_depth must be grater than 2\"\n",
    "        self.pos = PositionalEncoding(pos_embed_dim, max_seq_len)\n",
    "        self.fnn = nn.Sequential(\n",
    "            nn.Linear(pos_embed_dim, fnn_hidden_size),\n",
    "            Sin(fnn_hidden_size, freq, learn)\n",
    "        )\n",
    "        \n",
    "        for _ in range(fnn_depth - 2):\n",
    "            self.fnn.append(nn.Linear(fnn_hidden_size, fnn_hidden_size))\n",
    "            self.fnn.append(Sin(fnn_hidden_size, freq, learn))\n",
    "        self.fnn.append(nn.Linear(fnn_hidden_size, order * seq_embed_dim, bias=False))\n",
    "        \n",
    "        self.embed_dim = seq_embed_dim\n",
    "        self.order = order\n",
    "        self.window = ExponentialDecayWindow(\n",
    "            seq_embed_dim,\n",
    "            fast_decay_t=fast_decay_t,\n",
    "            slow_decay_t=slow_decay_t,\n",
    "            target=target,\n",
    "            shift=shift\n",
    "        )\n",
    "        \n",
    "    def forward(self, seq_len: int) -> list[Tensor]:\n",
    "        # L: seq len, Ep: pos embed dim, N: order of hyena, E: seq embed dim\n",
    "        t, z = self.pos(seq_len) # -> (1, 1, L), (L, Ep)\n",
    "        h = (\n",
    "            self.fnn(z) # (L, Ep) -> (L, N*E)\n",
    "            .transpose(0, 1) # (L, N*E) -> (N*E, L)\n",
    "            .reshape(self.order, self.embed_dim, seq_len) # (N*E, L) -> (N, E, L)\n",
    "        )\n",
    "        h = self.window(h, t) # (N, E, L) -> (N, E, L)\n",
    "        return h.chunk(self.order, dim=0) # (N, E, L) -> [(1, E, L)] * N\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyenaBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        embed_dim: int,\n",
    "        max_seq_len: int,\n",
    "        order: int,\n",
    "        pos_dim: int = 65,\n",
    "        kernel_size: int = 3,\n",
    "        stride: int = 1,\n",
    "        padding: int = 2,\n",
    "        fnn_depth: int = 4,\n",
    "        fnn_hidden_size: int = 64,\n",
    "        freq: float = 8.0,\n",
    "        learn_filter: bool = True,\n",
    "        fast_decay_t: float = 0.3,\n",
    "        slow_decay_t: float = 1.5,\n",
    "        target: float = 1e-2,\n",
    "        shift: float = 0.0,\n",
    "        activation: str = \"identity\"\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.proj = Projection(\n",
    "            embed_dim,\n",
    "            order,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=stride,\n",
    "            padding=padding\n",
    "        )\n",
    "        self.hyena_filter = HyenaFilter(\n",
    "            pos_dim,\n",
    "            max_seq_len,\n",
    "            seq_embed_dim=embed_dim,\n",
    "            order=order,\n",
    "            fnn_depth=fnn_depth,\n",
    "            fnn_hidden_size=fnn_hidden_size,\n",
    "            freq=freq,\n",
    "            learn=learn_filter,\n",
    "            fast_decay_t=fast_decay_t,\n",
    "            slow_decay_t=slow_decay_t,\n",
    "            target=target,\n",
    "            shift=shift\n",
    "        )\n",
    "        self.bias = nn.Parameter(torch.randn(order, 1, embed_dim, 1))\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.fc = nn.Linear(embed_dim, embed_dim)\n",
    "\n",
    "        act: nn.Module\n",
    "        match name := activation.lower():\n",
    "            case \"identity\": act = nn.Identity()\n",
    "            case \"relu\": act = nn.ReLU()\n",
    "            case \"leaky-relu\": act = nn.LeakyReLU()\n",
    "            case \"gelu\": act = nn.GELU()\n",
    "            case \"silu\": act = nn.SiLU()\n",
    "            case \"tanh\": act = nn.Tanh()\n",
    "            case _: raise NotImplementedError(f\"activation `{name}` is invalid\")\n",
    "        self.act = act\n",
    "\n",
    "    @staticmethod\n",
    "    def fftconv(x: Tensor, h: Tensor, d: Tensor) -> Tensor:\n",
    "        # B: batch size, L: seq len, E: embed dim\n",
    "        L = x.shape[-1]\n",
    "        h_fft = torch.fft.rfft(h, n=2*L, norm=\"forward\") # (1, E, L) -> (1, E, 2*L)\n",
    "        x_fft = torch.fft.rfft(x.to(dtype=h.dtype), n=2*L) # (B, E, L) -> (B, E, 2*L)\n",
    "        y = torch.fft.irfft(x_fft * h_fft, n=2*L, norm=\"forward\")[..., :L] # -> (B, E, L)\n",
    "        y += x * d\n",
    "        return y.to(dtype=x.dtype)\n",
    "\n",
    "    def forward(self, u: Tensor) -> Tensor:\n",
    "        # B: batch size, L: seq len, E: embed dim, N: order of hyena\n",
    "        L = u.shape[1]\n",
    "        x = self.norm1(u) # (B, L, E) -> (B, L, E)\n",
    "        ### hyena \n",
    "        x = self.proj(x) # (B, L, E) -> [(B, E, L)] * (N+1)\n",
    "        h = self.hyena_filter(L) # -> [(1, E, L)] * N\n",
    "        v = x[-1] # -> (B, E, L)\n",
    "        for x_i, h_i, d_i in zip(x[:-1], h, self.bias):\n",
    "            v = x_i * self.fftconv(v, h_i, d_i)\n",
    "        ###\n",
    "        y = u + v.transpose(1, 2) # -> (B, L, E)\n",
    "        out = self.norm2(y) # (B, L, E) -> (B, L, E)\n",
    "        out = self.fc(out) # (B, L, E) -> (B, L, E)\n",
    "        out = self.act(out) # (B, L, E) -> (B, L, E)\n",
    "        out += y\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "hb = HyenaBlock(embed_dim=3, max_seq_len=224*224, order=3) #order = 3 -> v x1, x2, x3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "u = torch.randn(1,224*224,3, requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Patching(nn.Module):\n",
    "    def __init__(self, patch_size):\n",
    "        \"\"\" [input]\n",
    "            - patch_size (int) : パッチの縦の長さ（=横の長さ）\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net = Rearrange(\"b c (h ph) (w pw) -> b (h w) (ph pw c)\", ph = patch_size, pw = patch_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\" [input]\n",
    "            - x (torch.Tensor) : 画像データ\n",
    "                - x.shape = torch.Size([batch_size, channels, image_height, image_width])\n",
    "        \"\"\"\n",
    "        x = self.net(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearProjection(nn.Module):\n",
    "    def __init__(self, patch_dim, embed_dim):\n",
    "        \"\"\" [input]\n",
    "            - patch_dim (int) : 一枚あたりのパッチの次元（= channels * (patch_size ** 2)\n",
    "            - dim (int) : パッチが変換されたベクトルの次元 \n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.net = nn.Linear(patch_dim, embed_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\" [input]\n",
    "            - x (torch.Tensor) \n",
    "                - x.shape = torch.Size([batch_size, n_patches, patch_dim])\n",
    "        \"\"\"\n",
    "        x = self.net(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from PIL import Image\n",
    "img = np.array(Image.open(\"../images/hyena.jpg\").resize((224,224)))\n",
    "img = torch.Tensor(img).unsqueeze(0)\n",
    "img = rearrange(img, \"b h w c -> b c h w\")\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784, 192])"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patching = Patching(patch_size=8)\n",
    "patching(img).shape # b (h w) (ph pw c) <=> b N C*P*P\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 784, 3])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lp = LinearProjection(patch_dim=192, embed_dim=3)\n",
    "lp(patching(img)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150528"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "224*224*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hyena",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
